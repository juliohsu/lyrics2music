{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries, modules and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert lyrics to music in midi format model\n",
    "class Lyrics2MusicModel(nn.Module):\n",
    "    def __init__(self, text_emb_size, input_size, hidden_size, output_size, num_heads, num_layers):\n",
    "        super(Lyrics2MusicModel, self).__init__()\n",
    "        # music embedding layer\n",
    "        self.music_emb = nn.Embedding(num_embeddings=input_size, embedding_dim=hidden_size)\n",
    "        # text encoder layer\n",
    "        self.text_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=hidden_size, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        # music decoder layer\n",
    "        self.music_decoder = nn.TransformerDecoder(\n",
    "            nn.TransformerDecoderLayer(d_model=hidden_size, nhead=num_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        # full connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, music_input, text_input):\n",
    "        music_emb = self.music_emb(music_input)\n",
    "\n",
    "        text_emb = self.text_encoder(text_input)\n",
    "        # duplicate text embedding shape toward music embedding\n",
    "        text_emb_repeated = text_emb.unsqueeze(0).repeat(music_emb.size(0), 1, 1)\n",
    "\n",
    "        # concat music and text embedding into one embedding (text conditioning)\n",
    "        conditioned_emb = music_emb + text_emb_repeated\n",
    "\n",
    "        # decode the embedding to midi output\n",
    "        midi_format_output = self.music_decoder(conditioned_emb)\n",
    "        return self.fc(midi_format_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for the gpu available condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets Collecting & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "sequence_length = 100\n",
    "\n",
    "# find out dataset for lyrics and music that is syncronized\n",
    "dataloader = []\n",
    "\n",
    "dataloader.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "model = Lyrics2MusicModel(input_size=128, hidden_size=512, output_size=128, num_heads=8, num_layers=6).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "\n",
    "# training epoch\n",
    "for epoch in range(epochs):\n",
    "    for music_input, text_input, target_output in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(music_input, text_input)\n",
    "        loss = criterion(output, target_output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"epoch {epoch}, loss: {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
